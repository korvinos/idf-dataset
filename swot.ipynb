{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from cftime import date2num\n",
    "from tqdm import tqdm\n",
    "from urllib.request import Request, urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download SWOT tif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 94/293 [01:14<02:41,  1.23it/s]"
     ]
    }
   ],
   "source": [
    "# Download SWOT data\n",
    "def downlad_swot_data(\n",
    "        url:str,\n",
    "        dst:str,\n",
    "        download:bool) -> list:\n",
    "    \"\"\" \n",
    "    Download SWOT tif files from the http\n",
    "    \"\"\"\n",
    "    urls = []\n",
    "    url = url.replace(\" \",\"%20\")\n",
    "    req = Request(url)\n",
    "    a = urlopen(req).read()\n",
    "    soup = BeautifulSoup(a, 'html.parser')\n",
    "    x = (soup.find_all('a'))\n",
    "    for i in tqdm(x):\n",
    "        file_name = i.extract().get_text()\n",
    "        url_new = url + file_name\n",
    "        url_new = url_new.replace(\" \",\"%20\")\n",
    "        if url_new.endswith('tif'):\n",
    "            f_name = Path(url_new).name\n",
    "            urls.append(url_new)\n",
    "            if download:\n",
    "                urlretrieve(url_new, dst / f_name)\n",
    "    return urls\n",
    "\n",
    "src = \"https://data.aviso.altimetry.fr/aviso-gateway/data/swot-adac/norwegiansea-lofotenbasin/\"\n",
    "dst = Path('dev/swot_data/lofoten/')\n",
    "url_list = downlad_swot_data(src, dst, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert SWOT data to the IDF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF_TIME_UNITS = 'days since 1970-01-01 00:00:00.000000Z'\n",
    "\n",
    "IDF_BANDS = {\n",
    "    'lat_gcp': {\n",
    "        'dimensions': ('row_gcp', 'cell_gcp'),\n",
    "        'datatype': 'f4',\n",
    "        'metadata': {\n",
    "            'long_name': 'ground control points latitude',\n",
    "            'standard_name': 'latitude',\n",
    "            'units': 'degrees_north',\n",
    "            'axis': 'Y',\n",
    "            'comment': 'geographical coordinates, WGS84 projection'}},\n",
    "    'lon_gcp': {\n",
    "        'dimensions': ('row_gcp', 'cell_gcp'),\n",
    "        'datatype': 'f4',\n",
    "        'metadata': {\n",
    "            'long_name': 'ground control points longitude',\n",
    "            'standard_name': 'longitude',\n",
    "            'units': 'degrees_east',\n",
    "            'axis': 'X',\n",
    "            'comment': 'geographical coordinates, WGS84 projection'}},\n",
    "    'index_row_gcp': {\n",
    "        'dimensions': ('row_gcp'),\n",
    "        'datatype': np.int32,\n",
    "        'metadata': {\n",
    "            'long_name': 'index of ground control points in row dimension',\n",
    "            'comment': 'index goes from 0 (start of first pixel) to dimension value (end of last pixel)'}},\n",
    "    'index_cell_gcp': {\n",
    "        'dimensions': ('cell_gcp'),\n",
    "        'datatype': np.int32,\n",
    "        'metadata': {\n",
    "            'long_name': 'index of ground control points in cell dimension',\n",
    "            'comment': 'index goes from 0 (start of first pixel) to dimension value (end of last pixel)'}},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 82/113 [00:18<00:07,  4.40it/s]\n"
     ]
    },
    {
     "ename": "RasterioIOError",
     "evalue": "dev/swot_data/lofoten/norwegiansea-lofotenbasin_20230430_p005_ssh.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pyidf/lib/python3.11/site-packages/xarray/backends/file_manager.py:210\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_key]\n\u001b[1;32m    211\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pyidf/lib/python3.11/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache[key]\n\u001b[1;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<function open at 0x139cf6200>, (PosixPath('dev/swot_data/lofoten/norwegiansea-lofotenbasin_20230430_p005_ssh.tif'),), 'r', (('sharing', False),), 'cf9584e9-d24f-4e54-b500-0f30a09a4975']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mrasterio/_base.pyx:310\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_base.pyx:221\u001b[0m, in \u001b[0;36mrasterio._base.open_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:221\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: dev/swot_data/lofoten/norwegiansea-lofotenbasin_20230430_p005_ssh.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m ssh_uri \u001b[39m=\u001b[39m s0_uri\u001b[39m.\u001b[39mparent \u001b[39m/\u001b[39m s0_uri\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39msig0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mssh\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m swot_s0 \u001b[39m=\u001b[39m rioxarray\u001b[39m.\u001b[39mopen_rasterio(s0_uri)\n\u001b[0;32m---> 15\u001b[0m swot_ssh \u001b[39m=\u001b[39m rioxarray\u001b[39m.\u001b[39;49mopen_rasterio(ssh_uri)\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ssh_uri\u001b[39m.\u001b[39mexists() \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m s0_uri\u001b[39m.\u001b[39mexists():\n\u001b[1;32m     18\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pyidf/lib/python3.11/site-packages/rioxarray/_io.py:1124\u001b[0m, in \u001b[0;36mopen_rasterio\u001b[0;34m(filename, parse_coordinates, chunks, cache, lock, masked, mask_and_scale, variable, group, default_name, decode_times, decode_timedelta, band_as_variable, **open_kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1123\u001b[0m         manager \u001b[39m=\u001b[39m URIManager(file_opener, filename, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, kwargs\u001b[39m=\u001b[39mopen_kwargs)\n\u001b[0;32m-> 1124\u001b[0m     riods \u001b[39m=\u001b[39m manager\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m   1125\u001b[0m     captured_warnings \u001b[39m=\u001b[39m rio_warnings\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m   1127\u001b[0m \u001b[39m# raise the NotGeoreferencedWarning if applicable\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pyidf/lib/python3.11/site-packages/xarray/backends/file_manager.py:192\u001b[0m, in \u001b[0;36mCachingFileManager.acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macquire\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    178\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Acquire a file object from the manager.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \n\u001b[1;32m    180\u001b[0m \u001b[39m    A new file is only opened if it has expired from the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m        An open file object, as returned by ``opener(*args, **kwargs)``.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m     file, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_acquire_with_cache_info(needs_lock)\n\u001b[1;32m    193\u001b[0m     \u001b[39mreturn\u001b[39;00m file\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pyidf/lib/python3.11/site-packages/xarray/backends/file_manager.py:216\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    214\u001b[0m     kwargs \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    215\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode\n\u001b[0;32m--> 216\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_opener(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    218\u001b[0m     \u001b[39m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pyidf/lib/python3.11/site-packages/rasterio/env.py:451\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    448\u001b[0m     session \u001b[39m=\u001b[39m DummySession()\n\u001b[1;32m    450\u001b[0m \u001b[39mwith\u001b[39;00m env_ctor(session\u001b[39m=\u001b[39msession):\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pyidf/lib/python3.11/site-packages/rasterio/__init__.py:304\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m path \u001b[39m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 304\u001b[0m     dataset \u001b[39m=\u001b[39m DatasetReader(path, driver\u001b[39m=\u001b[39;49mdriver, sharing\u001b[39m=\u001b[39;49msharing, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    305\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    306\u001b[0m     dataset \u001b[39m=\u001b[39m get_writer_for_path(path, driver\u001b[39m=\u001b[39mdriver)(\n\u001b[1;32m    307\u001b[0m         path, mode, driver\u001b[39m=\u001b[39mdriver, sharing\u001b[39m=\u001b[39msharing, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    308\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_base.pyx:312\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: dev/swot_data/lofoten/norwegiansea-lofotenbasin_20230430_p005_ssh.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "\n",
    "def gen_gcp_ids(size, step):\n",
    "    # NOTE: last gcp id should be the last row or cell\n",
    "    gcp_ids = list(np.arange(0, size, step)) + [size - 1]\n",
    "    return gcp_ids\n",
    "\n",
    "# Define the path with swot .tif files\n",
    "src_root = Path('dev/swot_data/lofoten/')\n",
    "dst_root = src_root / 'idf'\n",
    "dst_root.mkdir(exist_ok=True)\n",
    "\n",
    "for uri in tqdm(list(src_root.glob('*sig0.tif'))):\n",
    "    s0_uri = Path(uri)\n",
    "    ssh_uri = s0_uri.parent / s0_uri.name.replace('sig0', 'ssh')\n",
    "    \n",
    "    if not ssh_uri.exists() or not s0_uri.exists():\n",
    "        continue\n",
    "\n",
    "    swot_s0 = rioxarray.open_rasterio(s0_uri)\n",
    "    swot_ssh = rioxarray.open_rasterio(ssh_uri)\n",
    "\n",
    "    \n",
    "    lon_grd, lat_grd  = np.meshgrid(swot_s0.x.data, swot_s0.y.data)\n",
    "\n",
    "    s0_data = swot_s0[0,:,:].data\n",
    "    s0_data[swot_s0[3,:,:].data == 0] = 25\n",
    "\n",
    "\n",
    "    ssh_data = swot_ssh[0,:,:].data\n",
    "    ssh_data[swot_ssh[3,:,:].data == 0] = 25\n",
    "\n",
    "    out_ds = xr.Dataset(\n",
    "        data_vars=dict(\n",
    "            sigma0=(['time', 'row', 'cell'], [s0_data], {'_FillValue': 25}),\n",
    "            ssh=(['time', 'row', 'cell'], [ssh_data], {'_FillValue': 25})),\n",
    "        coords=dict(\n",
    "            lat=(['row', 'cell'], lat_grd),\n",
    "            lon=(['row', 'cell'], lon_grd)))\n",
    "\n",
    "    if s0_uri.stem.split('_')[-2] == 'p005':\n",
    "        time_start = datetime.strptime(s0_uri.stem.split('_')[1], '%Y%m%d') + timedelta(hours=1)\n",
    "        idf_filename = '_'.join([s0_uri.stem, f'{s0_uri.stem.split(\"_\")[1]}01Z_idf_00.nc'])\n",
    "    elif s0_uri.stem.split('_')[-2] == 'p014':\n",
    "        time_start = datetime.strptime(s0_uri.stem.split('_')[1], '%Y%m%d') + timedelta(hours=6)\n",
    "        idf_filename = '_'.join([s0_uri.stem, f'{s0_uri.stem.split(\"_\")[1]}06Z_idf_00.nc'])\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    time_end = time_start  + timedelta(hours=1)\n",
    "\n",
    "    out_ds['time'] = xr.DataArray(\n",
    "            [date2num(time_start, IDF_TIME_UNITS)], dims=['time'], \n",
    "            attrs=dict(units=IDF_TIME_UNITS, long_name='time', standard_name='time', calendar='gregorian'))\n",
    "\n",
    "    out_ds = out_ds.assign_attrs({\n",
    "            'idf_version': 1.0,\n",
    "            'idf_subsampling_factor': 0,\n",
    "            'idf_spatial_resolution': 1000,\n",
    "            'idf_spatial_resolution_units': 'm', \n",
    "            'idf_granule_id': idf_filename.replace('.nc', ''),\n",
    "            'time_coverage_start': f'{time_start:%Y-%m-%dT%H:%M:%S}.000000Z',\n",
    "            'time_coverage_end': f'{time_end:%Y-%m-%dT%H:%M:%S}.000000Z'\n",
    "        })\n",
    "\n",
    "        # Add idf GCP variables\n",
    "    gcp_ids_row = gen_gcp_ids(out_ds.row.size, 10)\n",
    "    gcp_ids_cell = gen_gcp_ids(out_ds.cell.size, 10)\n",
    "    out_ds = out_ds.assign(\n",
    "            lat_gcp=(['row_gcp', 'cell_gcp'], out_ds['lat'].data[gcp_ids_row, :][:, gcp_ids_cell], IDF_BANDS['lat_gcp']['metadata']),\n",
    "            lon_gcp=(['row_gcp', 'cell_gcp'], out_ds['lon'].data[gcp_ids_row, :][:, gcp_ids_cell], IDF_BANDS['lon_gcp']['metadata']),\n",
    "            index_row_gcp=(['row_gcp'], gcp_ids_row, IDF_BANDS['index_row_gcp']['metadata']),\n",
    "            index_cell_gcp=(['cell_gcp'], gcp_ids_cell, IDF_BANDS['index_cell_gcp']['metadata']))\n",
    "\n",
    "    out_ds = out_ds.drop_vars(['lat', 'lon'])\n",
    "\n",
    "    out_ds.to_netcdf(dst_root / idf_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not ssh_uri.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
